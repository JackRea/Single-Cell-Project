{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0f669e42020dcbe0110983b84f49315ea95156214cdc1256d3541f61dd3de87e0",
   "display_name": "Python 3.8.8 64-bit ('work': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "f669e42020dcbe0110983b84f49315ea95156214cdc1256d3541f61dd3de87e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Imports.\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "from scipy.stats import kstest\n",
    "from scipy.stats import poisson\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import t\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "from statsmodels.stats.gof import gof_binning_discrete\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn import mixture\n",
    "\n",
    "\n",
    "from scipy import linalg\n",
    "import matplotlib as mpl\n",
    "from collections import Counter\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load the calls data\n",
    "Clean it a bit\n",
    "'''\n",
    "segment_size = 5000000\n",
    "calls_data = pd.read_csv('DataFrames/calls.tsv', sep='\\t')\n",
    "calls_data['#CHR'] = pd.to_numeric(calls_data['#CHR'].str.replace('chr', ''))\n",
    "calls_data = calls_data.sort_values(['CELL', '#CHR', 'START']).reset_index(drop=True)\n",
    "calls_data['SEGMENT'] = ((calls_data['START'] > 0) & (calls_data['START'] % segment_size == 0)).cumsum()\n",
    "calls_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Functions\n",
    "'''\n",
    "# def spikiness(x):\n",
    "#     if sum(x) == 0:\n",
    "#         return np.nan\n",
    "#     else:\n",
    "#         return sum(abs(np.diff(x))) / sum(x)\n",
    "\n",
    "def count_spikiness(x):\n",
    "    return (sum(abs(x[1:].values - x[:-1].values)) / sum(x.values))\n",
    "\n",
    "def rdr_spikiness(x):\n",
    "    return 1/(sum(abs(x[1:].values - x[:-1].values)) / sum(x.values))\n",
    "\n",
    "def mean_distance(x):\n",
    "    st_vals = abs(x-x.mean())\n",
    "    distance = 1/(1+sum(st_vals))\n",
    "    return distance\n",
    "\n",
    "def count_t(x):\n",
    "    _centred = x - x.mean()\n",
    "    return kstest(rvs=_centred, cdf='t', N=len(_centred), args=(1, ))[1]\n",
    "\n",
    "def rdr_t(x):\n",
    "    scaled_x = x * 100\n",
    "    _centred = scaled_x - scaled_x.mean()\n",
    "    return kstest(rvs=_centred, cdf='t', N=len(_centred), args=(1, ))[1]\n",
    "\n",
    "def count_poisson(x):\n",
    "    (obsfreq, expfreq, histg) = gof_binning_discrete(x, poisson, arg=(x.mean(),))\n",
    "    return chisquare(obsfreq, expfreq, axis=None)[1]\n",
    "\n",
    "def rdr_poisson(x):\n",
    "    scaled_x = x * 100\n",
    "    (obsfreq, expfreq, histg) = gof_binning_discrete(scaled_x, poisson, arg=(scaled_x.mean(),))\n",
    "    return chisquare(obsfreq, expfreq, axis=None)[1]\n",
    "\n",
    "def count_variance(x):\n",
    "    _centred = x - x.mean()\n",
    "    return _centred.var()\n",
    "\n",
    "def rdr_variance(x):\n",
    "    scaled_x = x * 100\n",
    "    _centred = scaled_x - scaled_x.mean()\n",
    "    return _centred.var()\n",
    "\n",
    "count_poisson.__name__ = 'Poisson Score'\n",
    "rdr_poisson.__name__ = 'Poisson Score'\n",
    "count_t.__name__ = 'T Score'\n",
    "rdr_t.__name__ = 'T Score'\n",
    "mean_distance.__name__ = 'Distance metric'\n",
    "count_variance.__name__ = 'Variance'\n",
    "rdr_variance.__name__ = 'Variance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "P values per segment\n",
    "'''\n",
    "pvaldf = calls_data.groupby(['CELL', '#CHR', 'SEGMENT'], sort=False, as_index=False).agg({\n",
    "    'COUNT': [count_t, count_poisson, count_variance, mean_distance],\n",
    "    'RDR': [rdr_t, rdr_poisson, rdr_variance, mean_distance]\n",
    "    })\n",
    "pvaldf.to_csv('DataFrames/Segment_pvalues.csv')\n",
    "# pvaldf = pd.read_csv('DataFrames/Segment_pvalues.csv', index_col=[0])\n",
    "pvaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Remove np.inf, NaN and convert from multiindex\n",
    "'''\n",
    "pvaldf = pvaldf.replace([np.inf, -np.inf], np.nan)\n",
    "print(f'NaN values:\\n\\n{pvaldf.isna().sum()}')\n",
    "clean_pvaldf = pvaldf.dropna()\n",
    "clean_pvaldf.columns = clean_pvaldf.columns.map(' '.join).str.strip()\n",
    "clean_pvaldf.to_csv('DataFrames/Clean_Segment_pvalues.csv')\n",
    "# clean_pvaldf = pd.read_csv('DataFrames/Clean_Segment_pvalues.csv', index_col=[0])\n",
    "clean_pvaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Compute Spikiness\n",
    "'''\n",
    "spikiness_df = calls_data.groupby('CELL', sort=False, as_index=False).agg({'COUNT': count_spikiness, 'RDR': rdr_spikiness})\n",
    "spikiness_df.to_csv('DataFrames/Spikiness.csv')\n",
    "# spikiness_df = pd.read_csv('DataFrames/Spikiness.csv', index_col = [0])\n",
    "spikiness_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Bring everything together\n",
    "'''\n",
    "# combined_df = clean_pvaldf.groupby('CELL', sort=False, as_index=False).agg({column: 'median' for column in clean_pvaldf.columns.drop(['CELL', '#CHR', 'SEGMENT'])})\n",
    "# combined_df['COUNT Spikiness'] = spikiness_df['COUNT'].values\n",
    "# combined_df['RDR Spikiness'] = spikiness_df['RDR'].values\n",
    "# combined_df.to_csv('DataFrames/Combined_pvalues.csv')\n",
    "combined_df = pd.read_csv('DataFrames/Combined_pvalues.csv', index_col=[0])\n",
    "combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Plot Results\n",
    "'''\n",
    "fig = plt.figure(tight_layout=True, figsize=(16,16))\n",
    "gs = fig.add_gridspec(4,12)\n",
    "fig_ax1 = fig.add_subplot(gs[0, :3])\n",
    "fig_ax2 = fig.add_subplot(gs[0, 3:6])\n",
    "fig_ax3 = fig.add_subplot(gs[0, 6:9])\n",
    "fig_ax4 = fig.add_subplot(gs[0, 9:12])\n",
    "fig_ax5 = fig.add_subplot(gs[1, :3])\n",
    "fig_ax6 = fig.add_subplot(gs[1, 3:6])\n",
    "fig_ax7 = fig.add_subplot(gs[1, 6:9])\n",
    "fig_ax8 = fig.add_subplot(gs[1, 9:12])\n",
    "fig_ax9 = fig.add_subplot(gs[2, :3])\n",
    "fig_ax10 = fig.add_subplot(gs[2, 3:6])\n",
    "fig_ax11 = fig.add_subplot(gs[2, 6:9])\n",
    "fig_ax12 = fig.add_subplot(gs[2, 9:12])\n",
    "fig_ax13 = fig.add_subplot(gs[3, :3])\n",
    "fig_ax14 = fig.add_subplot(gs[3, 3:6])\n",
    "fig_ax15 = fig.add_subplot(gs[3, 6:9])\n",
    "fig_ax16 = fig.add_subplot(gs[3, 9:12])\n",
    "\n",
    "cph = sns.histplot(data=combined_df, x='COUNT Poisson Score', color='red', bins=50, ax=fig_ax1)\n",
    "cpv = sns.scatterplot(data=combined_df, x='COUNT Variance', color='blue', y='COUNT Poisson Score', ax=fig_ax2)\n",
    "rph = sns.histplot(data=combined_df, x='RDR Poisson Score', color='black', bins=50, ax=fig_ax3)\n",
    "rpv = sns.scatterplot(data=combined_df, x='RDR Variance', y='RDR Poisson Score', color='orange', ax=fig_ax4)\n",
    "\n",
    "cth = sns.histplot(data=combined_df, x='COUNT T Score', color='red', bins=50, ax=fig_ax5)\n",
    "ctv = sns.scatterplot(data=combined_df, x='COUNT Variance', y='COUNT T Score', color='blue', ax=fig_ax6)\n",
    "rth = sns.histplot(data=combined_df, x='RDR T Score',color='black', bins=50, ax=fig_ax7)\n",
    "rtv = sns.scatterplot(data=combined_df, x='RDR Variance', y='RDR T Score', color='orange', ax=fig_ax8)\n",
    "\n",
    "csh = sns.histplot(data=combined_df, x='COUNT Spikiness', color='red', bins=50, ax=fig_ax9)\n",
    "css = sns.scatterplot(data=combined_df, x='COUNT Variance', y='COUNT Spikiness', color='blue', ax=fig_ax10)\n",
    "csh = sns.histplot(data=combined_df, x='RDR Spikiness', bins=50, color='black', ax=fig_ax11)\n",
    "css = sns.scatterplot(data=combined_df, x='RDR Variance', y='RDR Spikiness', color='orange', ax=fig_ax12)\n",
    "\n",
    "a = sns.histplot(data=combined_df, x='COUNT Distance metric', color='red', bins=50, ax=fig_ax13)\n",
    "b = sns.scatterplot(data=combined_df, x='COUNT Variance', y='COUNT Distance metric', color='blue', ax=fig_ax14)\n",
    "c = sns.histplot(data=combined_df, x='RDR Distance metric', bins=50, color='black', ax=fig_ax15)\n",
    "d = sns.scatterplot(data=combined_df, x='RDR Variance', y='RDR Distance metric', color='orange', ax=fig_ax16)\n",
    "\n",
    "fig.savefig('Raw Figures/Methods_overall.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Look at these plots against total count number\n",
    "'''\n",
    "count_number_df = combined_df.copy()\n",
    "total_counts = calls_data.groupby('CELL', sort=False, as_index=False).agg({'COUNT':'sum', 'RDR': 'sum'})\n",
    "count_number_df['TOTAL COUNT'] = total_counts['COUNT']\n",
    "count_number_df['TOTAL RDR'] = total_counts['RDR']\n",
    "\n",
    "\n",
    "\n",
    "def _plot(axis, method):\n",
    "    scatter = sns.scatterplot(data=count_number_df, x='TOTAL COUNT', y=method,color='black' if axis <=3 else 'orange', ax=axs[axis,0] if axis <=3 else axs[axis-4,1])\n",
    "    scatter.set_ylim()\n",
    "    scatter.set_yticks([])\n",
    "    scatter.set_ylabel('')\n",
    "    scatter.text(0.6, 0.8, f'{method}',fontsize=5,transform=scatter.transAxes)\n",
    "\n",
    "\n",
    "methods = count_number_df.columns.drop(['CELL', 'COUNT Variance', 'RDR Variance', 'TOTAL COUNT', 'TOTAL RDR']).sort_values()\n",
    "fig, axs = plt.subplots(int(len(methods)/2), 2, figsize=(20,20), tight_layout=True)\n",
    "grphs = list(map(lambda method: _plot(*method), enumerate(methods)))\n",
    "fig.savefig('Raw Figures/Total_count.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Look at cell plots for each\n",
    "'''\n",
    "plotting_df = combined_df.copy()\n",
    "good_bad_dict = {x: [plotting_df.sort_values(x, ascending=False).head(1)['CELL'].values[0], plotting_df.sort_values(x, ascending=False).tail(1)['CELL'].values[0]] for x in plotting_df.columns.drop(['CELL', 'COUNT Variance', 'RDR Variance']).sort_values()}\n",
    "\n",
    "gs_kw = dict(width_ratios=[2] * 2, height_ratios=[1] * 8)\n",
    "figs, axes = plt.subplots(8, 2, constrained_layout=True, figsize=(70, 50), gridspec_kw=gs_kw, sharex='col', sharey='col')\n",
    "figs.suptitle('Method Performance', fontsize='xx-large')\n",
    "figs.set_constrained_layout_pads(w_pad=25/72, h_pad=25/72, hspace=0.05, wspace=0.05)\n",
    "\n",
    "rnum = -1\n",
    "for num, (method, cells) in enumerate(good_bad_dict.items()):\n",
    "    for cell in cells:\n",
    "        rnum += 1\n",
    "        cell_df = calls_data[calls_data['CELL'] == cell].copy()\n",
    "        cell_df['Position'] = cell_df['START'].cumsum()\n",
    "        s = sns.scatterplot(data=cell_df, x='Position', y='COUNT' if num <= 3 else 'RDR',color='orange' if num <= 3 else 'black',legend=False, ax=axes[rnum, 0] if num <= 3 else axes[rnum - 8, 1])\n",
    "        s.set_title(f'BEST - method: {method}' if rnum % 2 == 0 else f'WORST - method: {method}')\n",
    "        s.set_xlim(0, cell_df['Position'].max())\n",
    "        s.set_ylim((0, 150) if num <= 3 else (None, None))\n",
    "        s.text(0.8, 1.1, f'Variance: {plotting_df[plotting_df[\"CELL\"] == cell][\"COUNT Variance\"].values}' if num <= 3 else f'Variance: {plotting_df[plotting_df[\"CELL\"] == cell][\"RDR Variance\"].values}', bbox=dict(facecolor='red', alpha=0.5), transform=s.transAxes)\n",
    "        vlines = list(map(lambda x: s.axvline(x), cell_df.drop_duplicates('#CHR', keep='last')['Position']))\n",
    "\n",
    "figs.savefig('Raw Figures/Performance.pdf', format='pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plot boxplots for all metrics for clone and no clone cells\n",
    "'''\n",
    "mappings_data = pd.read_csv('DataFrames/mapping.tsv', sep='\\t')\n",
    "clone_df = combined_df.copy()\n",
    "clone_df['Clone'] = clone_df['CELL'].isin(mappings_data[mappings_data['CLONE'] != 'None']['#CELL'].reset_index(drop=True))\n",
    "clone_df = clone_df.replace([True, False], ['Has clone', 'No clone'])\n",
    "\n",
    "methods = clone_df.columns.drop(['CELL', 'Clone']).sort_values()\n",
    "\n",
    "fig, axs = plt.subplots(len(methods), figsize=(25,100), tight_layout=True, sharex=True)\n",
    "boxplots = list(map(lambda enum: _plot(enum[0], enum[1]), enumerate(methods)))\n",
    "fig.savefig('Raw Figures/Boxplots.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Take example cells and plot them\n",
    "\n",
    "\n",
    "rdr = count bin/count nm bin x mn total counts/total counts\n",
    "'''\n",
    "random_cell_plot_df = combined_df.copy()\n",
    "random_cell_choice = random.choice(random_cell_plot_df['CELL'].unique())\n",
    "cellcalls = calls_data[calls_data['CELL'] == random_cell_choice].copy()\n",
    "cellcalls['TOTCOUNT'] = cellcalls['START'].cumsum()\n",
    "metrics = random_cell_plot_df[random_cell_plot_df['CELL'] == random_cell_choice]\n",
    "print(f'Average counts: {cellcalls[\"COUNT\"].mean()}\\t Variance counts: {cellcalls[\"COUNT\"].var()}')\n",
    "print(f'Average rdr: {cellcalls[\"RDR\"].mean()}\\t Variance rdr: {cellcalls[\"RDR\"].var()}')\n",
    "print(f'T:{metrics[\"COUNT T Score\"].values[0]}')\n",
    "\n",
    "fig, ax = plt.subplots(2,1,tight_layout=True, figsize=(30,20))\n",
    "scatp = sns.scatterplot(data=cellcalls, x='TOTCOUNT', y='COUNT', ax=ax[0])\n",
    "scatp.set_ylim(0,200)\n",
    "scatr = sns.scatterplot(data=cellcalls, x='TOTCOUNT', y='RDR', ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''clustering'''\n",
    "cell_segment_df = calls_data[(calls_data['CELL'] == 'AAACCTGGTACCAGTT') & (calls_data['SEGMENT'] == 1167)].copy()\n",
    "count_array = cell_segment_df['RDR'].values.reshape(-1, 1)\n",
    "start_array = cell_segment_df['START'].values.reshape(-1, 1)\n",
    "_X = np.concatenate((start_array, count_array), axis=1)\n",
    "gmm = BayesianGaussianMixture(n_components=10).fit(count_array)\n",
    "\n",
    "color_iter = itertools.cycle(['navy', 'c', 'cornflowerblue', 'gold', 'darkorange'])\n",
    "fig, ax = plt.subplots(figsize=(16,10))\n",
    "def plot_results(X, Y_, means, covariances, index, title):\n",
    "    splot = plt.subplot(2, 1, 1 + index)\n",
    "    for i, (mean, covar, color) in enumerate(zip(\n",
    "            means, covariances, color_iter)):\n",
    "        v, w = linalg.eigh(covar)\n",
    "        v = 2. * np.sqrt(2.) * np.sqrt(v)\n",
    "        u = w[0] / linalg.norm(w[0])\n",
    "        if not np.any(Y_ == i):\n",
    "            continue\n",
    "        plt.scatter(X[Y_ == i, 0], X[Y_ == i, 1], 5, color='black')\n",
    "        angle = np.arctan(u[1] / u[0])\n",
    "        angle = 180. * angle / np.pi\n",
    "        ell = mpl.patches.Ellipse(mean, v[0], v[1], 180. + angle, color=color)\n",
    "        ell.set_clip_box(splot.bbox)\n",
    "        ell.set_alpha(0.5)\n",
    "        splot.add_artist(ell)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title(title)\n",
    "\n",
    "dpgmm = mixture.BayesianGaussianMixture(n_components=10, covariance_type='full', weight_concentration_prior=0.01, weight_concentration_prior_type='dirichlet_distribution',mean_precision_prior=1e-2, max_iter=100).fit(_X)\n",
    "plot_results(_X, dpgmm.predict(_X), dpgmm.means_, dpgmm.covariances_, 1, '')\n",
    "\n",
    "fig.savefig('Thesis Figures/clustering.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''clustering'''\n",
    "def plot_data(X):\n",
    "    plt.plot(X[:, 0], X[:, 1], 'k.', markersize=2)\n",
    "\n",
    "def plot_centroids(centroids, weights=None, circle_color='w', cross_color='k'):\n",
    "    if weights is not None:\n",
    "        centroids = centroids[weights > weights.max() / 10]\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "                marker='o', s=35, linewidths=8,\n",
    "                color=circle_color, zorder=10, alpha=0.9)\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "                marker='x', s=2, linewidths=12,\n",
    "                color=cross_color, zorder=11, alpha=1)\n",
    "\n",
    "def plot_gaussian_mixture(clusterer, X, resolution=1000, show_ylabels=True):\n",
    "    mins = X.min(axis=0) - 0.1\n",
    "    maxs = X.max(axis=0) + 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(mins[0], maxs[0], resolution),\n",
    "                         np.linspace(mins[1], maxs[1], resolution))\n",
    "    Z = -clusterer.score_samples(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.contourf(xx, yy, Z,\n",
    "                 norm=LogNorm(vmin=1.0, vmax=30.0),\n",
    "                 levels=np.logspace(0, 2, 12))\n",
    "    plt.contour(xx, yy, Z,\n",
    "                norm=LogNorm(vmin=1.0, vmax=30.0),\n",
    "                levels=np.logspace(0, 2, 12),\n",
    "                linewidths=1, colors='k')\n",
    "\n",
    "    Z = clusterer.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contour(xx, yy, Z,\n",
    "                linewidths=2, colors='r', linestyles='dashed')\n",
    "    \n",
    "    plt.plot(X[:, 0], X[:, 1], 'k.', markersize=2)\n",
    "    plot_centroids(clusterer.means_, clusterer.weights_)\n",
    "\n",
    "    plt.xlabel(\"$x_1$\", fontsize=14)\n",
    "    if show_ylabels:\n",
    "        plt.ylabel(\"$x_2$\", fontsize=14, rotation=0)\n",
    "    else:\n",
    "        plt.tick_params(labelleft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''clustering'''\n",
    "plt.figure(figsize=(8, 4))\n",
    "plot_gaussian_mixture(dpgmm, _X)\n",
    "plt.savefig('Thesis Figures/clustering2.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "clustering percent function\n",
    "'''\n",
    "def segment_clustering(series):\n",
    "    num_components = 10\n",
    "    if len(series) < num_components:\n",
    "        return np.nan\n",
    "    array = series.values.reshape(-1,1)\n",
    "    number_of_clusters = BayesianGaussianMixture(n_components=num_components, covariance_type='full', weight_concentration_prior=0.01, weight_concentration_prior_type='dirichlet_distribution', mean_precision_prior=1e-2, n_init=3,max_iter=100).fit_predict(array)\n",
    "    most_common_cluster = np.bincount(number_of_clusters).argmax()\n",
    "    deviant_assignments = np.count_nonzero(number_of_clusters != most_common_cluster)\n",
    "    return deviant_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''pre clustering - segment sampling'''\n",
    "number_of_samples = 50\n",
    "\n",
    "pre_cluster = calls_data.copy()\n",
    "\n",
    "segment_lst = list(itertools.chain(*[random.sample(range(sub['SEGMENT'].min(), sub['SEGMENT'].max()), number_of_samples) for cell, sub in pre_cluster.groupby('CELL', sort=False)]))\n",
    "\n",
    "precluster_df = pre_cluster[pre_cluster['SEGMENT'].isin(segment_lst)].reset_index(drop=True)\n",
    "precluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''clustering'''\n",
    "# cluster_df = precluster_df.groupby(['CELL', 'SEGMENT'], sort=False, as_index=False).agg({'COUNT': segment_clustering, 'RDR': segment_clustering})\n",
    "# cluster_df.to_csv('DataFrames/clustering_df_50samples.csv')\n",
    "cluster_df = pd.read_csv('DataFrames/clustering_df_50samples.csv')\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cluster_cell = cluster_df.groupby('CELL', sort=False, as_index=False).agg({'COUNT': 'sum', 'RDR': 'sum'})\n",
    "cell_total_bin_lst = list(map(lambda x: len(precluster_df[precluster_df['CELL'] == x]), total_cluster_cell['CELL'].unique()))\n",
    "total_cluster_cell['TOTAL BINS'] = cell_total_bin_lst\n",
    "total_cluster_cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cluster_cell['COUNT PERCENTAGE'] = (total_cluster_cell['COUNT'] / total_cluster_cell['TOTAL BINS']) * 100\n",
    "total_cluster_cell['RDR PERCENTAGE'] = (total_cluster_cell['RDR'] / total_cluster_cell['TOTAL BINS']) * 100\n",
    "total_cluster_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,tight_layout=True, sharey=True)\n",
    "s = sns.histplot(data=total_cluster_cell, x='COUNT PERCENTAGE', bins=50, color='red', ax=ax[0])\n",
    "s.set_title('Percentages for read counts');s.set_xlabel('')\n",
    "sr = sns.histplot(data=total_cluster_cell, x='RDR PERCENTAGE', bins=50, color='black', ax=ax[1])\n",
    "sr.set_title('Percentages for RDR');sr.set_xlabel('')\n",
    "fig.savefig('Thesis Figures/percentage_distribution.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_oi = total_cluster_cell[(total_cluster_cell['RDR PERCENTAGE'] > 9) & (total_cluster_cell['RDR PERCENTAGE'] < 10)]\n",
    "data_oi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_oi = data_oi['CELL'].unique()\n",
    "count_t_scores = combined_df[combined_df['CELL'].isin(cells_oi)]\n",
    "\n",
    "fig, ax = plt.subplots(2,2, tight_layout=True, sharex='col', sharey='row', figsize=(12,12))\n",
    "s1 = sns.boxplot(data=count_t_scores, color='red',x='COUNT T Score', ax=ax[0,0])\n",
    "s2 = sns.boxplot(data=count_t_scores, color='black',x='RDR T Score', ax=ax[0,1])\n",
    "s1.set_title('Read counts')\n",
    "s2.set_title('RDR')\n",
    "s1.set_ylabel('')\n",
    "s2.set_ylabel('')\n",
    "h1 = sns.histplot(data=combined_df, x='COUNT T Score', color='red', bins=50, ax=ax[1,0])\n",
    "h2 = sns.histplot(data=combined_df, x='RDR T Score', color='black', bins=50, ax=ax[1,1])\n",
    "h1.axvline(count_t_scores['COUNT T Score'].median(), color='green', label='Threshold')\n",
    "h2.axvline(count_t_scores['RDR T Score'].median(), color='green', label='Threshold')\n",
    "h1.legend()\n",
    "h2.legend()\n",
    "fig.suptitle('Boxplots for reference cells used to infer cutoff for all cells', fontsize=16)\n",
    "\n",
    "fig.savefig('Thesis Figures/Boxplot_threshold.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(combined_df[combined_df['COUNT T Score'] > count_t_scores['COUNT T Score'].median()]) / 1829) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(combined_df[combined_df['RDR T Score'] > count_t_scores['RDR T Score'].median()]) / 1829) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_cells = combined_df[combined_df['RDR T Score'] > count_t_scores['RDR T Score'].median()]['CELL'].values\n",
    "\n",
    "calls_data['QUALITY'] = calls_data['CELL'].isin(good_cells)\n",
    "calls_data = calls_data.replace(True, 'Good')\n",
    "calls_data = calls_data.replace(False, 'Bad')\n",
    "calls_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['QUALITY'] = combined_df['CELL'].isin(good_cells)\n",
    "combined_df = combined_df.replace([True, False], ['Good', 'Bad'])\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "f = sns.boxplot(data=combined_df, x='QUALITY', y='RDR Variance')\n",
    "f.set_ylabel('Variance')\n",
    "fig.savefig('Thesis Figures/GoodBadBoxplot.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings_data = pd.read_csv('DataFrames/mapping.tsv', sep='\\t')\n",
    "cells_with_clone = mappings_data[mappings_data['CLONE'] != 'None']['#CELL'].values\n",
    "combined_df['CLONE'] = combined_df['CELL'].isin(cells_with_clone)\n",
    "combined_df = combined_df.replace([True, False], ['Has Clone', 'No Clone'])\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = combined_df[combined_df['CLONE'] == 'No Clone'].copy()\n",
    "xb = combined_df[(combined_df['CLONE'] == 'No Clone') & (combined_df['QUALITY'] == 'Bad')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_bad = (len(xb) / len(x)) * 100\n",
    "percent_bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}