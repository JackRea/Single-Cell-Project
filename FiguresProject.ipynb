{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from sklearn.covariance import MinCovDet\n",
    "\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "from statsmodels.graphics.gofplots import qqplot_2samples\n",
    "\n",
    "from scipy.stats import poisson\n",
    "from scipy.stats import norm\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "sns.set_style('whitegrid')\n",
    "'''\n",
    "some good color maps:\n",
    " - CMRmap\n",
    " - Dark2\n",
    " - Paired\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Variance as measure of dispersion\n",
    "'''\n",
    "number_values = 50\n",
    "variances = [1, 10, 50, 200]\n",
    "label_height_adjust, label_width_adjust = 3, -5\n",
    "\n",
    "values = lambda variance: norm.rvs(0, math.sqrt(variance), size=number_values, random_state=42)\n",
    "dffunc = lambda values: pd.DataFrame({'values': values}).explode('values').reset_index(drop=True)\n",
    "df = dffunc(list(map(values, variances)))\n",
    "df['Color'] = ((df.index.values % number_values == 0) & (df.index.values > 0)).cumsum()\n",
    "\n",
    "grid_kw={'wspace': 0}\n",
    "fig, ax = plt.subplots(1,2,figsize=(16,10), gridspec_kw=grid_kw)\n",
    "sc = sns.scatterplot(data=df, x=df.index, y='values', hue='Color', palette='Dark2', legend=False, ax=ax[0])\n",
    "kde = sns.kdeplot(data=df.astype(float), y='values', hue='Color', palette='Dark2', legend=False, ax=ax[1])\n",
    "kde.axis('off')\n",
    "sc.axis((0, len(df), None, None))\n",
    "sc.set_xlabel('Segment examples');sc.set_xticks([]);sc.set_yticks([]);sc.set_ylabel('')\n",
    "vlines = list(map(lambda x: sc.axvline(x, color='black',alpha=1, lw=0.5), \\\n",
    "            range(0, len(df), number_values)))\n",
    "hline = sc.axhline(0, color='black')\n",
    "labels = list(map(lambda zipped: sc.text(zipped[0] + label_width_adjust, df['values'].max() + \\\n",
    "            label_height_adjust, s=f'Variance: {zipped[1]}'), zip(range(int(number_values/3), \\\n",
    "            len(df), number_values), variances)))\n",
    "fig.savefig('Thesis Figures/Variance_demo.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Combining 20kb into 5MB\n",
    "'''\n",
    "segment_size = 5000000\n",
    "calls_data = pd.read_csv('DataFrames/calls.tsv', sep='\\t')\n",
    "calls_data['#CHR'] = pd.to_numeric(calls_data['#CHR'].str.replace('chr', ''))\n",
    "calls_data = calls_data.sort_values(['CELL', '#CHR', 'START']).reset_index(drop=True)\n",
    "calls_data['SEGMENT'] = ((calls_data['START'] > 0) & (calls_data['START'] % segment_size == 0)).cumsum()\n",
    "calls_data = calls_data[['#CHR', 'CELL', 'START', 'END', 'COUNT', 'RDR', 'SEGMENT']]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "the_table = ax.table(cellText=calls_data[:25].values, colLabels=calls_data[:25].columns, loc='center', colColours=['lightgray'] * 14)\n",
    "pp = PdfPages(\"Thesis Figures/Calls_segment.pdf\")\n",
    "pp.savefig(fig, bbox_inches='tight')\n",
    "pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Random Cell plot\n",
    "'''\n",
    "y_height = -6\n",
    "\n",
    "random_cell_df = calls_data[calls_data['CELL'] == 'TCAGGATAGACCACGA'].copy().reset_index(drop=True)\n",
    "random_cell_df['TOTAL'] = random_cell_df['START'].cumsum()\n",
    "end_of_chromosomes = random_cell_df.drop_duplicates('#CHR', keep='last').reset_index(drop=True)['TOTAL'].values\n",
    "_positions = np.insert(end_of_chromosomes, 0, 0)\n",
    "positions = (_positions[1:] + _positions[:-1]) / 2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(30,8))\n",
    "sc = sns.scatterplot(data=random_cell_df, x='TOTAL', y='COUNT', hue='#CHR', palette='Dark2', legend=False, ax=ax)\n",
    "sc.axis((0, random_cell_df['TOTAL'].max(), 0, 100))\n",
    "sc.set_xticks([]);sc.set_yticks([]);sc.set_xlabel('');sc.set_ylabel('COUNT')\n",
    "vlines = list(map(lambda x: sc.axvline(x, color='black',alpha=1, lw=0.5), end_of_chromosomes))\n",
    "chr_labels = list(map(lambda position:sc.text(position[1], y_height, f'Chr{position[0]}',\\\n",
    "             rotation='vertical', transform=sc.transData), enumerate(positions, start=1)))\n",
    "\n",
    "fig.savefig('Thesis Figures/cell.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dispersion for counts and RDR (Poisson plot)\n",
    "'''\n",
    "dispersion_df = calls_data.groupby(['CELL', '#CHR', 'SEGMENT'], sort=False, as_index=False).agg({'COUNT': ['mean', 'var'], \\\n",
    "                'RDR': ['mean', 'var']})\n",
    "dispersion_df.columns = dispersion_df.columns.map(' '.join).str.strip()\n",
    "dispersion_df = dispersion_df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "sample_dispersion = dispersion_df.sample(50000)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, tight_layout=True)\n",
    "for name in ['COUNT', 'RDR']:\n",
    "    sc = sns.scatterplot(data=sample_dispersion, x=f'{name} mean',y=f'{name} var', \\\n",
    "         color='black' if name == 'COUNT' else 'orange',ax=ax[0] if name == 'COUNT' else ax[1])\n",
    "    sc.axis((0, None, 0, sample_dispersion[f'{name} mean'].max()))\n",
    "    line = sns.lineplot(data=sample_dispersion, x=f'{name} mean', y=f'{name} mean', ax=ax[0] if name == 'COUNT' else ax[1])\n",
    "fig.savefig('Thesis figures/overdispersion.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_df = calls_data.groupby(['CELL', '#CHR'], sort=False, as_index=False).agg({'COUNT': 'sum', 'RDR': 'sum'})\n",
    "heatmap_dict_count = {cell: [sub['COUNT'].to_numpy()] for (cell, sub) in heatmap_df.groupby('CELL', sort=False, as_index=False)}\n",
    "heatmap_dict_rdr = {cell: [sub['RDR'].to_numpy()] for (cell, sub) in heatmap_df.groupby('CELL', sort=False, as_index=False)}\n",
    "\n",
    "count_array = np.concatenate(list(heatmap_dict_count.values()))\n",
    "rdr_array = np.concatenate(list(heatmap_dict_rdr.values()))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,2,tight_layout=True, figsize=(16,10), sharey=True)\n",
    "c = sns.heatmap(count_array, xticklabels=1, yticklabels=False,cmap='Oranges', ax=ax[0])\n",
    "r = sns.heatmap(rdr_array, xticklabels=1, yticklabels=False, cmap='Blues',ax=ax[1])\n",
    "\n",
    "c.set_ylabel('Cell')\n",
    "c.set_title('Count heatmap')\n",
    "r.set_title('RDR heatmap')\n",
    "\n",
    "fig.savefig('Thesis Figures/Heatmaps.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "RESULT - PERFORMANCE\n",
    "'''\n",
    "combined_df =  pd.read_csv('DataFrames/Combined_pvalues.csv', index_col=[0])\n",
    "methods = combined_df.columns.drop(['CELL', 'COUNT Variance', 'RDR Variance']).sort_values()\n",
    "\n",
    "grid_kw, sub_kw = {'wspace': 0.4, 'hspace': 0.2}, {}\n",
    "fig, ax = plt.subplots(4, 4, figsize=(30,24), gridspec_kw=grid_kw, subplot_kw=sub_kw)\n",
    "hist_plots = list(map(lambda method: sns.histplot(data=combined_df, x=method[1], color='red' if method[0] <= 3 else 'black', bins=50, ax=ax[method[0], 0] if method[0] <= 3 else ax[method[0] - 4, 2]), enumerate(methods)))\n",
    "sc_plots = list(map(lambda method: sns.scatterplot(data=combined_df, x='COUNT Variance' if method[0] <= 3 else 'RDR Variance', y=method[1], color='blue' if method[0] <= 3 else 'orange', ax=ax[method[0], 1] if method[0] <= 3 else ax[method[0] - 4, 3]), enumerate(methods)))\n",
    "limits = list(map(lambda x: x.axis((0, None, 0, 35)), ([x[0] for x in ax] + [x[2] for x in ax])))\n",
    "\n",
    "fig.savefig('Thesis Figures/Performance.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "performance against total counts\n",
    "'''\n",
    "count_number_df = pd.read_csv('DataFrames/Combined_pvalues.csv', index_col=[0]).copy()\n",
    "total_counts = calls_data.groupby('CELL', sort=False, as_index=False).agg({'COUNT':'sum', 'RDR': 'sum'})\n",
    "count_number_df['TOTAL COUNT'] = total_counts['COUNT']\n",
    "count_number_df['TOTAL RDR'] = total_counts['RDR']\n",
    "\n",
    "\n",
    "\n",
    "def _plot(axis, method):\n",
    "    scatter = sns.scatterplot(data=count_number_df, x='TOTAL COUNT', y=method, color='blue', ax=axs[axis])\n",
    "    scatter.set_ylim()\n",
    "    scatter.set_yticks([])\n",
    "    scatter.set_xticks([])\n",
    "    scatter.set_ylabel('')\n",
    "    scatter.set_title(method)\n",
    "\n",
    "\n",
    "methods = count_number_df.columns.drop(['CELL', 'COUNT Variance', 'RDR Variance', 'TOTAL COUNT', 'TOTAL RDR', 'RDR Distance metric', 'RDR Poisson Score','RDR Spikiness', 'RDR T Score']).sort_values()\n",
    "methods\n",
    "fig, axs = plt.subplots(1,int(len(methods)), figsize=(16,6), tight_layout=True)\n",
    "grphs = list(map(lambda method: _plot(*method), enumerate(methods)))\n",
    "fig.savefig('Thesis Figures/Performance_against_total_count.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CELL plots for good and bad for each method\n",
    "'''\n",
    "plotting_df = combined_df.copy()\n",
    "good_bad_dict = {x: [plotting_df.sort_values(x, ascending=False).head(1)['CELL'].values[0], plotting_df.sort_values(x, ascending=False).tail(1)['CELL'].values[0]] for x in plotting_df.columns.drop(['CELL', 'COUNT Variance', 'RDR Variance']).sort_values()}\n",
    "\n",
    "gs_kw = dict(width_ratios=[2] * 2, height_ratios=[1] * 8)\n",
    "figs, axes = plt.subplots(8, 2, constrained_layout=True, figsize=(70, 50), gridspec_kw=gs_kw, sharex='col', sharey='col')\n",
    "figs.suptitle('Method Performance', fontsize='xx-large')\n",
    "figs.set_constrained_layout_pads(w_pad=25/72, h_pad=25/72, hspace=0.05, wspace=0.05)\n",
    "\n",
    "rnum = -1\n",
    "for num, (method, cells) in enumerate(good_bad_dict.items()):\n",
    "    for cell in cells:\n",
    "        rnum += 1\n",
    "        cell_df = calls_data[calls_data['CELL'] == cell].copy()\n",
    "        cell_df['Position'] = cell_df['START'].cumsum()\n",
    "        s = sns.scatterplot(data=cell_df, x='Position', y='COUNT' if num <= 3 else 'RDR',color='orange' if num <= 3 else 'black',legend=False, ax=axes[rnum, 0] if num <= 3 else axes[rnum - 8, 1])\n",
    "        s.set_title(f'BEST - method: {method}' if rnum % 2 == 0 else f'WORST - method: {method}')\n",
    "        s.set_xlim(0, cell_df['Position'].max())\n",
    "        s.set_ylim((0, 150) if num <= 3 else (None, None))\n",
    "        s.text(0.8, 1.1, f'Variance: {plotting_df[plotting_df[\"CELL\"] == cell][\"COUNT Variance\"].values}' if num <= 3 else f'Variance: {plotting_df[plotting_df[\"CELL\"] == cell][\"RDR Variance\"].values}', bbox=dict(facecolor='red', alpha=0.5), transform=s.transAxes)\n",
    "        vlines = list(map(lambda x: s.axvline(x), cell_df.drop_duplicates('#CHR', keep='last')['Position']))\n",
    "\n",
    "figs.savefig('Thesis Figures/CELLS_from_method.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "T distirbution good and bad cells\n",
    "'''\n",
    "count_number_df = pd.read_csv('DataFrames/Combined_pvalues.csv', index_col=[0]).sort_values('COUNT T Score', ascending=False)\n",
    "best_cell, worst_cell = count_number_df['CELL'].head(1).values[0], count_number_df['CELL'].tail(1).values[0]\n",
    "\n",
    "fig, ax = plt.subplots(2,1)\n",
    "for num,cell in enumerate([best_cell, worst_cell]):\n",
    "    plot = calls_data[calls_data['CELL'] == cell].copy()\n",
    "    sns.scatterplot(data=plot, x='TOTAL', y='COUNT', ax=ax[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Variance figure\n",
    "'''\n",
    "\"\"\"\n",
    "----Methods----\n",
    "Often times covariance is calculated instead of varaince but since VAR(X) = COVAR(X,X), for univariate uniform guassions\n",
    "the covariance is the variance.\n",
    "Most of these rely on covariance calculators from SKlearn.\n",
    "'ML'         - is a maximum likelihood method.\n",
    "'GMM'        - is a gaussian mixture mdodel. The default assumed normals is one, using anything more than this is mostlikely\n",
    "               pointless as all the observations come from a uniform normal distribution. Better to test this on an actual\n",
    "               sample of counts across the cell?\n",
    "'BGMM'       - is a bayesian gaussian mixture model. Again the sample problem applies.\n",
    "'EC'         - is the empirical covariance. This is also a maximum likelihood estimate.\n",
    "'EE'         - is the eliptical envelope, useful for detecting outliers, but included anyway.\n",
    "'LEDOIT WOLF'- calculates estimates using shrinkage.\n",
    "'MINCOVDET'  - is minimum covariance determinant. Good robust estimator of covariance; uses empiral covariance.\n",
    "There are a lot of hyperparams that  can be tweaked.\n",
    "\"\"\"\n",
    "true_mean, true_std = 1, 0.4\n",
    "errors = []\n",
    "methods = ['ML', 'GMM', 'BGMM', 'EC', 'EE', 'LEDOIT WOLF', 'MINCOVDET']\n",
    "for method in methods:\n",
    "    for observations in [10, 100, 1000, 10000]:\n",
    "        for repeats in range(1,1001):\n",
    "            Data = np.random.normal(true_mean, true_std, observations)\n",
    "            if method == 'ML':\n",
    "                mu, sigma = norm.fit(Data)\n",
    "            elif method == 'GMM':\n",
    "                gm = GaussianMixture().fit(Data.reshape(-1,1))\n",
    "                mu, sigma = gm.means_[0][0], math.sqrt(gm.covariances_[0][0])\n",
    "            elif method == 'BGMM':\n",
    "                bgm = BayesianGaussianMixture().fit(Data.reshape(-1,1))\n",
    "                mu, sigma = bgm.means_[0][0], math.sqrt(bgm.covariances_[0][0])\n",
    "            elif method == 'EC':\n",
    "                cov = EmpiricalCovariance().fit(Data.reshape(-1,1))\n",
    "                mu, sigma = cov.location_[0], math.sqrt(cov.covariance_[0])\n",
    "            elif method == 'EE':\n",
    "                cov = EllipticEnvelope().fit(Data.reshape(-1,1))\n",
    "                mu, sigma = cov.location_[0], math.sqrt(cov.covariance_[0])\n",
    "            elif method == 'LEDOIT WOLF':\n",
    "                cov = LedoitWolf().fit(Data.reshape(-1,1))\n",
    "                mu, sigma = cov.location_[0], math.sqrt(cov.covariance_[0])\n",
    "            elif method == 'MINCOVDET':\n",
    "                cov = MinCovDet().fit(Data.reshape(-1,1))\n",
    "                mu, sigma = cov.location_[0], math.sqrt(cov.covariance_[0])\n",
    "            mean_error = abs((true_mean - mu) / true_mean)\n",
    "            std_error = abs((true_std - sigma) / true_std)\n",
    "            errors.append({'Mean error': mean_error, 'Standard deviation error': std_error, 'Observations':observations, 'Method': method})\n",
    "df = pd.DataFrame(errors)\n",
    "\n",
    "fig, axs = plt.subplots(1,4, figsize=(25,20), tight_layout=True, sharey=True)\n",
    "for number, value in enumerate([10,100,1000,10000]):\n",
    "    sns.boxplot(data=df[df['Observations'] == value], x='Observations', y='Standard deviation error', hue='Method', palette='Set1', ax=axs[number])\n",
    "    axs[number].legend(loc=2, fontsize='x-small', ncol=2, title='Legend (method used)')\n",
    "\n",
    "fig.savefig('Thesis Figures/Variance experiments.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "example qqplot with poisson\n",
    "'''\n",
    "fig, ax = plt.subplots(4, 3, tight_layout=True, sharey='row', sharex='col', figsize=(16,10))\n",
    "\n",
    "for num, variance in enumerate([10, 60, 150, 250]):\n",
    "    norm_values = np.array([int(rvs) for rvs in norm.rvs(loc=60, scale=math.sqrt(variance), size=250, random_state=113)])\n",
    "    pois_values = np.array([int(rvs) for rvs in poisson.rvs(mu=60, size=250, random_state=113)])\n",
    "    scat = sns.scatterplot(x=np.arange(len(norm_values)),y=norm_values, ax=ax[num, 0])\n",
    "    hist = sns.histplot(norm_values, ax=ax[num, 1])\n",
    "    qq = qqplot_2samples(ProbPlot(norm_values), ProbPlot(pois_values), line='45', ax=ax[num, 2])\n",
    "\n",
    "    ax[num, 0].set_title(f'Variance = {variance}, mean = 60')\n",
    "    ax[num, 2].set_title('')\n",
    "    ax[num, 2].set_xlabel('')\n",
    "    ax[num, 2].set_ylabel('')\n",
    "    ax[num, 1].set_xlim(left=20, right=105)\n",
    "    ax[num, 2].set_xlim(left=40, right=85)\n",
    "\n",
    "fig.savefig('Thesis Figures/poisson_qq.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}